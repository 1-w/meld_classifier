{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b82e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting MELD_DATA_PATH to /home/kw350/rds/rds-kw350-meld/meld_data/Data\n",
      "Setting BASE_PATH to /home/kw350/rds/rds-kw350-meld/meld_data/Data\n",
      "Setting EXPERIMENT_PATH to /rds/user/kw350/rds-kw350-meld/experiments/kw350/\n",
      "Setting FS_SUBJECTS_PATH to /home/kw350/rds/rds-kw350-meld/meld_data/Data/output/fs_outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from meld_classifier.paths import BASE_PATH, EXPERIMENT_PATH,MELD_DATA_PATH\n",
    "from meld_classifier.meld_cohort import MeldCohort, MeldSubject\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import neuroCombat as nc\n",
    "import meld_classifier.distributedCombat as dc\n",
    "import numpy as np\n",
    "# from pygam import LinearGAM,s\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c504144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_codes=['H2', 'H3','H4','H5','H6','H7','H9','H10','H11','H12','H14','H15','H16','H17','H18','H19',\n",
    "                  'H21','H23','H24','H26',]\n",
    "new_sites=['H27','H28']\n",
    "c_raw = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix.hdf5', dataset=None,\n",
    "                  data_dir=MELD_DATA_PATH)\n",
    "c_combat =  MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_combat_6.hdf5', dataset=None,\n",
    "                      data_dir=MELD_DATA_PATH)\n",
    "listids = c_combat.get_subject_ids(site_codes=site_codes, lesional_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb150a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old combat\n",
    "def combat_new_site(\n",
    "        self,\n",
    "        feature_name,\n",
    "        new_site_code,\n",
    "        ref_cohort,\n",
    "        new_outliers_file=None,\n",
    "    ):\n",
    "        \"\"\"Harmonise new site data to post-combat whole cohort and save in\n",
    "        new hdf5 file. New sites are run individually currently.\n",
    "        assumes that the base cohort is the post-combat cohort\n",
    "        Args:\n",
    "            feature_name (str): name of the feature\n",
    "            outliers_file : outliers file for the new cohort\n",
    "\n",
    "        \"\"\"\n",
    "        # read morphological outliers from new cohort only\n",
    "        if new_outliers_file is not None:\n",
    "            outliers = list(pd.read_csv(os.path.join(BASE_PATH, new_outliers_file), header=0)[\"ID\"])\n",
    "        else:\n",
    "            outliers = []\n",
    "\n",
    "        # make empty for all subjects\n",
    "        ref_subject_ids = ref_cohort.get_subject_ids(lesional_only=False)\n",
    "        combined_ids = ref_subject_ids + self.subject_ids\n",
    "        combat_subject_include = np.zeros(len(combined_ids), dtype=bool)\n",
    "        new_site_codes = np.ones(len(combined_ids), dtype=int)\n",
    "        new_site_codes[: len(ref_subject_ids)] = 0\n",
    "        # load in both combat normalised and new cohort\n",
    "        precombat_features = []\n",
    "        cohorts = [ref_cohort, self.cohort]\n",
    "        # need pre combat and post combat feature names, loading in post for the whole cohort,\n",
    "        # pre for the new cohort.\n",
    "        post_combat_feature_name = self.feat.combat_feat(feature_name)\n",
    "        feature_names = [post_combat_feature_name, feature_name]\n",
    "        for k, subject in enumerate(combined_ids):\n",
    "            # get the reference index and cohort object for the site, 0 whole cohort, 1 new cohort\n",
    "            site_code_index = new_site_codes[k]\n",
    "            cohort = cohorts[site_code_index]\n",
    "            subj = MeldSubject(subject, cohort=cohort)\n",
    "            # exclude outliers and subject without feature\n",
    "            if (subj.has_features(feature_names[site_code_index])) & (subject not in outliers):\n",
    "                lh = subj.load_feature_values(feature_names[site_code_index], hemi=\"lh\")[self.cohort.cortex_mask]\n",
    "                rh = subj.load_feature_values(feature_names[site_code_index], hemi=\"rh\")[self.cohort.cortex_mask]\n",
    "                combined_hemis = np.hstack([lh, rh])\n",
    "                precombat_features.append(combined_hemis)\n",
    "                combat_subject_include[k] = True\n",
    "            else:\n",
    "                combat_subject_include[k] = False\n",
    "        if precombat_features:\n",
    "            precombat_features = np.array(precombat_features)\n",
    "            # load in covariates - age, sex, group, site and scanner,\n",
    "            # set site_scanner to 0 for existing cohort\n",
    "            covars = pd.concat([self.load_covars(ref_subject_ids), self.covars])\n",
    "            covars[\"site_scanner\"][: len(ref_subject_ids)] = \"H0\"\n",
    "            covars = covars[combat_subject_include].copy()\n",
    "\n",
    "            # function to check for single subjects\n",
    "            covars, precombat_features = self.remove_isolated_subs(covars, precombat_features)\n",
    "\n",
    "            dict_combat = nc.neuroCombat(\n",
    "                precombat_features.T,\n",
    "                covars,\n",
    "                batch_col=\"site_scanner\",\n",
    "                categorical_cols=[\"sex\", \"group\"],\n",
    "                continuous_cols=[\"ages\"],\n",
    "                ref_batch=\"H0\",\n",
    "            )\n",
    "\n",
    "            print(\"Combat finished \\n Saving data\")\n",
    "            # only save out new subjects\n",
    "            ids_to_save = np.array(covars[covars[\"site_scanner\"] != \"H0\"][\"ID\"])\n",
    "            return dict_combat[\"data\"].T[covars[\"site_scanner\"] != \"H0\"]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195f801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new combat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1b831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('../../neuroCombat/distributedCombat/')\n",
    "import meld_classifier.distributedCombat as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7664fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroCombat as nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cd4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meld_classifier.data_preprocessing import Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2ac380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get full combat thing\n",
    "preprocessor=Preprocess(c_combat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e483cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distributed combat parameters for central site\n",
    "#check size\n",
    "#calculated distributed combat parameters for ref site\n",
    "\n",
    "#run combat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46aecb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in precombat data\n",
    "ref_subject_ids = c_combat.get_subject_ids(lesional_only=False)\n",
    "new_site_codes=np.zeros(len(ref_subject_ids))\n",
    "precombat_features=[]\n",
    "combat_subject_include = np.zeros(len(ref_subject_ids), dtype=bool)\n",
    "\n",
    "for k, subject in enumerate(ref_subject_ids):\n",
    "    # get the reference index and cohort object for the site, 0 whole cohort, 1 new cohort\n",
    "    site_code_index = new_site_codes[k]\n",
    "    \n",
    "    subj = MeldSubject(subject, cohort=c_combat)\n",
    "    # exclude outliers and subject without feature\n",
    "    if (subj.has_features('.combat.on_lh.thickness.sm10.mgh')) :\n",
    "        lh = subj.load_feature_values('.combat.on_lh.thickness.sm10.mgh', hemi=\"lh\")[c_combat.cortex_mask]\n",
    "        rh = subj.load_feature_values('.combat.on_lh.thickness.sm10.mgh', hemi=\"rh\")[c_combat.cortex_mask]\n",
    "        combined_hemis = np.hstack([lh, rh])\n",
    "        precombat_features.append(combined_hemis)\n",
    "        combat_subject_include[k] = True\n",
    "    else:\n",
    "        combat_subject_include[k] = False\n",
    "\n",
    "#calculate distributed combat parameters for central site\n",
    "precombat_features = np.array(precombat_features).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3bc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d342c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_site_code = 'H29'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acef543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/software/main_meld/meld_classifier/meld_classifier/data_preprocessing.py:129: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the transforming function.\n",
      "  covars[\"ages\"] = covars.groupby(\"site_scanner\").transform(lambda x: x.fillna(x.mean()))[\"ages\"]\n"
     ]
    }
   ],
   "source": [
    "covars = preprocessor.load_covars(ref_subject_ids)\n",
    "\n",
    "covars = covars[combat_subject_include].copy()\n",
    "covars = covars.reset_index()\n",
    "N=len(covars)\n",
    "bat = pd.Series(pd.Categorical(np.repeat('H0', N), categories=['H0', new_site_code]))\n",
    "\n",
    "covars['site_scanner']=bat\n",
    "covars = covars[['ages','sex','group','site_scanner']]\n",
    "# for c in ['ages','sex','group']:\n",
    "#     covars[c] = covars[c].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12044f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/software/main_meld/neuroCombat/neuroCombat/neuroCombat.py:324: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neuroCombat] Final adjustment of data\n"
     ]
    }
   ],
   "source": [
    "#use var estimates from basic combat\n",
    "com_out = nc.neuroCombat(precombat_features, covars, 'site_scanner')\n",
    "with open('MELD_var.pickle', \"wb\") as f:\n",
    "    pickle.dump(com_out['estimates']['var.pooled'], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c8a888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ls_site': [array([[944, 0.0, 23725.221764705886, 445.0, 571],\n",
       "         [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "         [23725.221764705886, 0.0, 789041.592005191, 11023.880000000005,\n",
       "          12905.221764705886],\n",
       "         [445.0, 0.0, 11023.880000000005, 445.0, 281.0],\n",
       "         [571, 0.0, 12905.221764705886, 281.0, 571]], dtype=object),\n",
       "  array([[2643.5596737861633, 2435.3595724105835, 2539.5392149686813, ...,\n",
       "          2965.045336127281, 2963.4483358860016, 2960.173226714134],\n",
       "         [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "         [66334.75930531249, 59975.292315540835, 62089.316403753786, ...,\n",
       "          74319.31836403435, 74276.7197474132, 74190.13579773683],\n",
       "         [1239.3644975423813, 1142.9102636575699, 1191.7604579925537, ...,\n",
       "          1375.2028512954712, 1372.8655278682709, 1370.22782766819],\n",
       "         [1585.3471558094025, 1473.0717936754227, 1540.9511893987656, ...,\n",
       "          1777.7451092004776, 1778.9316754341125, 1778.9515227079391]],\n",
       "        dtype=object)],\n",
       " 'data_dict': {'batch': 0      H0\n",
       "  1      H0\n",
       "  2      H0\n",
       "  3      H0\n",
       "  4      H0\n",
       "         ..\n",
       "  939    H0\n",
       "  940    H0\n",
       "  941    H0\n",
       "  942    H0\n",
       "  943    H0\n",
       "  Length: 944, dtype: category\n",
       "  Categories (2, object): ['H0', 'H29'],\n",
       "  'batches': [(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "            13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "            26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "            39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "            52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "            65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "            78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "            91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "           104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "           117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "           130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "           143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "           156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "           169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "           182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "           195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "           208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "           221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "           234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "           247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "           260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "           273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "           286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "           299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "           312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "           325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "           338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "           351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "           364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "           377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "           390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "           403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "           416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "           429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "           442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "           455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "           468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "           481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "           494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "           507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "           520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "           533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "           546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "           559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "           572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "           585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "           598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "           611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "           624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
       "           637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "           650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
       "           663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
       "           676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
       "           689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
       "           702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
       "           715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
       "           728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
       "           741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
       "           754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
       "           767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
       "           780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
       "           793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
       "           806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
       "           819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
       "           832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
       "           845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
       "           858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
       "           871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
       "           884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
       "           897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
       "           910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
       "           923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
       "           936, 937, 938, 939, 940, 941, 942, 943]),),\n",
       "   (array([], dtype=int64),)],\n",
       "  'n_batch': 2,\n",
       "  'n_batches': [944, 0],\n",
       "  'n_array': 944,\n",
       "  'n_covariates': 3,\n",
       "  'design':      batch[H0]  batch[H29]   ages  sex  group\n",
       "  0            1         0.0  21.00  1.0   True\n",
       "  1            1         0.0  26.00  1.0   True\n",
       "  2            1         0.0  25.00  1.0   True\n",
       "  3            1         0.0  31.00  0.0   True\n",
       "  4            1         0.0  25.75  0.0   True\n",
       "  ..         ...         ...    ...  ...    ...\n",
       "  939          1         0.0  12.00  0.0   True\n",
       "  940          1         0.0  11.00  0.0   True\n",
       "  941          1         0.0  11.00  1.0   True\n",
       "  942          1         0.0  10.00  0.0   True\n",
       "  943          1         0.0  13.00  1.0   True\n",
       "  \n",
       "  [944 rows x 5 columns],\n",
       "  'batch_design':      batch[H0]  batch[H29]\n",
       "  0            1         0.0\n",
       "  1            1         0.0\n",
       "  2            1         0.0\n",
       "  3            1         0.0\n",
       "  4            1         0.0\n",
       "  ..         ...         ...\n",
       "  939          1         0.0\n",
       "  940          1         0.0\n",
       "  941          1         0.0\n",
       "  942          1         0.0\n",
       "  943          1         0.0\n",
       "  \n",
       "  [944 rows x 2 columns],\n",
       "  'ref': 0,\n",
       "  'ref_batch': 'H0'},\n",
       " 'sigma_site': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate reference estimates for distributed combat\n",
    "_ = dc.distributedCombat_site(precombat_features, bat, covars[['ages','sex','group']], \n",
    "                          file='MELD.pickle', ref_batch = 'H0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca7463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/.conda/envs/meld_classifier/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#dummy new site data\n",
    "#get real new site data\n",
    "\n",
    "new_site_data = precombat_features[:,:20]\n",
    "new_site_covars = covars.loc[:19]\n",
    "new_site_covars['site_scanner']='H27'\n",
    "N=len(new_site_covars)\n",
    "bat = pd.Series(pd.Categorical(np.repeat(new_site_code, N),\n",
    "                               categories=['H0', new_site_code]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68c894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=dc.distributedCombat_site(new_site_data,\n",
    "                          bat, \n",
    "                          new_site_covars[['ages','sex','group']], \n",
    "                          file=\"new_site_summary.pickle\", \n",
    "                          ref_batch = 'H0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81686863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must specify filename to output results as a file. Currently saving output to current workspace only.\n"
     ]
    }
   ],
   "source": [
    "dc_out = dc.distributedCombat_central(\n",
    "    [\"MELD.pickle\", \"new_site_summary.pickle\"], ref_batch = 'H0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96132fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third, use variance estimates from full MELD cohort\n",
    "dc_out['var_pooled'] = pd.read_pickle('MELD_var.pickle').ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd63a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/.conda/envs/meld_classifier/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ages</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "      <th>site_scanner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>46.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ages  sex  group site_scanner\n",
       "0   21.00  1.0    1.0          H27\n",
       "1   26.00  1.0    1.0          H27\n",
       "2   25.00  1.0    1.0          H27\n",
       "3   31.00  0.0    1.0          H27\n",
       "4   25.75  0.0    1.0          H27\n",
       "5   23.00  0.0    1.0          H27\n",
       "6   30.00  1.0    1.0          H27\n",
       "7   21.00  0.0    1.0          H27\n",
       "8   38.00  0.0    1.0          H27\n",
       "9   45.00  0.0    1.0          H27\n",
       "10  61.00  0.0    1.0          H27\n",
       "11  24.00  0.0    1.0          H27\n",
       "12  17.00  0.0    1.0          H27\n",
       "13  35.00  0.0    1.0          H27\n",
       "14  25.00  1.0    1.0          H27\n",
       "15  17.00  1.0    1.0          H27\n",
       "16  35.00  0.0    1.0          H27\n",
       "17  36.00  0.0    1.0          H27\n",
       "18  46.00  0.0    1.0          H27\n",
       "19  56.00  0.0    1.0          H27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_site_covars[['ages','sex','group']]\n",
    "for c in ['ages','sex','group']:\n",
    "    new_site_covars[c]=new_site_covars[c].astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98a50294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/software/main_meld/meld_classifier/meld_classifier/distributedCombat_helpers.py:229: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  np.linalg.inv(np.matmul(batch_design.transpose(), batch_design)),\n",
      "/home/kw350/software/main_meld/meld_classifier/meld_classifier/distributedCombat_helpers.py:232: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  gamma_hat = np.matmul(gamma_hat, s_data.transpose())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dat_combat':               0         1         2         3         4         5         6   \\\n",
       " 0       2.595635  2.097938  3.026401  3.006287  2.896137  3.198391  2.897986   \n",
       " 1       2.463568  2.396726  2.765514  2.309976  2.887334  2.317723  2.747328   \n",
       " 2       2.826228  2.674310  2.865000  2.223642  2.794088  2.300700  2.202705   \n",
       " 3       2.331012  2.464350  2.418239  3.056799  2.389323  2.165172  2.220407   \n",
       " 4       2.924268  3.103857  2.582707  3.375710  3.176956  3.181451  2.834421   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 293799  2.437880  2.671439  3.144954  3.660862  3.169304  4.145481  3.260040   \n",
       " 293800  2.424257  2.682000  3.195341  3.639781  3.214105  4.160335  3.291214   \n",
       " 293801  2.409653  2.694118  3.240368  3.620041  3.254245  4.168916  3.323698   \n",
       " 293802  2.377067  2.661448  3.212721  3.623532  3.270908  4.182988  3.381572   \n",
       " 293803  2.348620  2.632386  3.182702  3.622817  3.282910  4.187874  3.432968   \n",
       " \n",
       "               7         8         9         10        11        12        13  \\\n",
       " 0       2.914676  2.894596  2.980496  2.864334  2.556620  3.171592  2.985002   \n",
       " 1       2.957874  1.931532  2.024018  1.758352  2.780079  2.651924  2.030183   \n",
       " 2       2.727768  2.255811  2.400951  2.409932  2.618288  2.328032  2.799634   \n",
       " 3       2.412758  2.519592  2.229470  1.925748  2.611118  2.579540  2.397235   \n",
       " 4       2.955556  2.872597  3.242691  2.699565  1.901427  2.655403  2.378384   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 293799  3.682636  3.317185  3.262666  3.447251  3.351943  2.782457  2.202078   \n",
       " 293800  3.692809  3.336342  3.271090  3.456684  3.417306  2.788439  2.197262   \n",
       " 293801  3.699357  3.357244  3.275693  3.462224  3.475426  2.793216  2.197693   \n",
       " 293802  3.712665  3.406078  3.240101  3.465668  3.511634  2.770940  2.217265   \n",
       " 293803  3.716098  3.451491  3.210661  3.460518  3.540851  2.750175  2.236324   \n",
       " \n",
       "               14        15        16        17        18        19  \n",
       " 0       2.729447  1.997988  2.868934  1.780917  2.529217  3.360249  \n",
       " 1       2.865259  1.656230  2.355527  2.983769  2.691782  2.781201  \n",
       " 2       2.654902  2.513126  2.478226  2.460181  3.175700  2.740131  \n",
       " 3       1.907576  2.586702  1.863725  2.382701  2.701477  2.439335  \n",
       " 4       2.409075  3.678869  3.298893  3.320930  3.101524  3.235494  \n",
       " ...          ...       ...       ...       ...       ...       ...  \n",
       " 293799  3.720586  2.326057  3.381557  3.354372  2.635463  3.397440  \n",
       " 293800  3.710026  2.351553  3.426638  3.404824  2.617439  3.426127  \n",
       " 293801  3.693916  2.371486  3.462564  3.445037  2.599037  3.448321  \n",
       " 293802  3.672249  2.347553  3.473150  3.435233  2.555386  3.402996  \n",
       " 293803  3.645471  2.329132  3.483074  3.419680  2.518235  3.354297  \n",
       " \n",
       " [293804 rows x 20 columns],\n",
       " 'estimates': {'gamma_hat':     0         1         2         3         4        5         6       \\\n",
       "  0 -0.03831 -0.256643 -0.248471 -0.056237  0.346352  0.12432 -0.185927   \n",
       "  \n",
       "       7        8         9       ...    293794   293795    293796    293797  \\\n",
       "  0 -0.134941 -0.03782  0.124881  ...  0.438246  0.43488  0.401767  0.366007   \n",
       "  \n",
       "       293798    293799    293800   293801    293802    293803  \n",
       "  0  0.329619  0.298492  0.298071  0.29426  0.261275  0.231819  \n",
       "  \n",
       "  [1 rows x 293804 columns],\n",
       "  'delta_hat': array([1.48970325, 1.36644794, 0.70786655, ..., 1.53180443, 1.52480839,\n",
       "         1.51541201]),\n",
       "  'gamma_star': array([-0.01966927, -0.09759911, -0.111213  , ...,  0.09385213,\n",
       "          0.08295549,  0.07320043]),\n",
       "  'delta_star': 0         1.248183\n",
       "  1         1.203827\n",
       "  2         0.899542\n",
       "  3         0.949990\n",
       "  4         1.325293\n",
       "              ...   \n",
       "  293799    1.284783\n",
       "  293800    1.286416\n",
       "  293801    1.286603\n",
       "  293802    1.279377\n",
       "  293803    1.271884\n",
       "  Length: 293804, dtype: float64,\n",
       "  'gamma_bar': -0.009737309006788568,\n",
       "  't2': array(0.03325185),\n",
       "  'a_prior': 11.773578729140649,\n",
       "  'b_prior': 11.773578729140649,\n",
       "  'stand_mean': array([[2.8783344 , 2.8783344 , 2.8783344 , ..., 2.8783344 , 2.8783344 ,\n",
       "          2.8783344 ],\n",
       "         [2.7866703 , 2.7866703 , 2.7866703 , ..., 2.7866703 , 2.7866703 ,\n",
       "          2.7866703 ],\n",
       "         [2.95501785, 2.95501785, 2.95501785, ..., 2.95501785, 2.95501785,\n",
       "          2.95501785],\n",
       "         ...,\n",
       "         [3.27262504, 3.27262504, 3.27262504, ..., 3.27262504, 3.27262504,\n",
       "          3.27262504],\n",
       "         [3.26695027, 3.26695027, 3.26695027, ..., 3.26695027, 3.26695027,\n",
       "          3.26695027],\n",
       "         [3.25935748, 3.25935748, 3.25935748, ..., 3.25935748, 3.25935748,\n",
       "          3.25935748]]),\n",
       "  'mod_mean':               0         1         2         3         4         5         6   \\\n",
       "  0      -0.116572 -0.121277 -0.120336 -0.094115 -0.089175 -0.086588 -0.125040   \n",
       "  1      -0.208653 -0.242419 -0.235666 -0.251365 -0.215911 -0.197339 -0.269432   \n",
       "  2      -0.255551 -0.301368 -0.292205 -0.319829 -0.271722 -0.246522 -0.338021   \n",
       "  3      -0.132218 -0.173806 -0.165489 -0.229348 -0.185680 -0.162806 -0.207077   \n",
       "  4      -0.251746 -0.287929 -0.280692 -0.267822 -0.229831 -0.209931 -0.316874   \n",
       "  ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "  293799 -0.208694 -0.214883 -0.213645 -0.127462 -0.120964 -0.117560 -0.219834   \n",
       "  293800 -0.208354 -0.215414 -0.214002 -0.126171 -0.118758 -0.114875 -0.221062   \n",
       "  293801 -0.206695 -0.214662 -0.213069 -0.124160 -0.115795 -0.111413 -0.221035   \n",
       "  293802 -0.202744 -0.210463 -0.208919 -0.112386 -0.104280 -0.100034 -0.216639   \n",
       "  293803 -0.197811 -0.205351 -0.203843 -0.101901 -0.093984 -0.089837 -0.211383   \n",
       "  \n",
       "                7         8         9         10        11        12        13  \\\n",
       "  0      -0.084706 -0.100701 -0.107287 -0.122341 -0.087529 -0.080943 -0.097879   \n",
       "  1      -0.183833 -0.298637 -0.345910 -0.453961 -0.204092 -0.156820 -0.278378   \n",
       "  2      -0.228196 -0.383973 -0.448116 -0.594729 -0.255686 -0.191542 -0.356483   \n",
       "  3      -0.146171 -0.287573 -0.345797 -0.478882 -0.171124 -0.112900 -0.262619   \n",
       "  4      -0.195458 -0.318478 -0.369133 -0.484916 -0.217167 -0.166512 -0.296768   \n",
       "  ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "  293799 -0.115084 -0.136127 -0.144792 -0.164596 -0.118798 -0.110133 -0.132413   \n",
       "  293800 -0.112051 -0.136054 -0.145938 -0.168530 -0.116287 -0.106403 -0.131819   \n",
       "  293801 -0.108227 -0.135314 -0.146467 -0.171961 -0.113007 -0.101853 -0.130534   \n",
       "  293802 -0.096947 -0.123193 -0.134000 -0.158703 -0.101578 -0.090771 -0.118561   \n",
       "  293803 -0.086821 -0.112457 -0.123013 -0.147140 -0.091345 -0.080789 -0.107933   \n",
       "  \n",
       "                14        15        16        17        18        19  \n",
       "  0      -0.120336 -0.112809 -0.097879 -0.098819 -0.108228 -0.117637  \n",
       "  1      -0.235666 -0.181640 -0.278378 -0.285131 -0.352663 -0.420195  \n",
       "  2      -0.292205 -0.218898 -0.356483 -0.365646 -0.457279 -0.548913  \n",
       "  3      -0.165489 -0.098946 -0.262619 -0.270937 -0.354115 -0.437293  \n",
       "  4      -0.280692 -0.222801 -0.296768 -0.304005 -0.376369 -0.448734  \n",
       "  ...          ...       ...       ...       ...       ...       ...  \n",
       "  293799 -0.213645 -0.203743 -0.132413 -0.133651 -0.146029 -0.158407  \n",
       "  293800 -0.214002 -0.202706 -0.131819 -0.133231 -0.147350 -0.161470  \n",
       "  293801 -0.213069 -0.200322 -0.130534 -0.132127 -0.148060 -0.163994  \n",
       "  293802 -0.208919 -0.196568 -0.118561 -0.120105 -0.135544 -0.150983  \n",
       "  293803 -0.203843 -0.191779 -0.107933 -0.109441 -0.124521 -0.139601  \n",
       "  \n",
       "  [293804 rows x 20 columns],\n",
       "  'var_pooled': array([0.13729922, 0.13914082, 0.10271709, ..., 0.21593729, 0.22392766,\n",
       "         0.23028035]),\n",
       "  'beta_hat': array([[ 2.87833440e+00,  2.78667030e+00,  2.95501785e+00, ...,\n",
       "           3.27262504e+00,  3.26695027e+00,  3.25935748e+00],\n",
       "         [-1.41954264e-02, -9.57320639e-02, -7.96337305e-02, ...,\n",
       "           1.36739717e-01,  1.23637882e-01,  1.11244211e-01],\n",
       "         [-9.40870468e-04, -6.75320918e-03, -9.16333961e-03, ...,\n",
       "          -1.59334917e-03, -1.54390978e-03, -1.50798058e-03],\n",
       "         [-3.18658186e-02, -2.48202471e-02, -2.73554812e-02, ...,\n",
       "          -9.84687448e-02, -1.05796869e-01, -1.10989548e-01],\n",
       "         [-6.49480714e-02, -4.20154066e-02, -3.57656471e-02, ...,\n",
       "          -7.47662797e-02, -6.45245369e-02, -5.51536097e-02]]),\n",
       "  'mod':      ages  sex  group\n",
       "  0   21.00  1.0    1.0\n",
       "  1   26.00  1.0    1.0\n",
       "  2   25.00  1.0    1.0\n",
       "  3   31.00  0.0    1.0\n",
       "  4   25.75  0.0    1.0\n",
       "  5   23.00  0.0    1.0\n",
       "  6   30.00  1.0    1.0\n",
       "  7   21.00  0.0    1.0\n",
       "  8   38.00  0.0    1.0\n",
       "  9   45.00  0.0    1.0\n",
       "  10  61.00  0.0    1.0\n",
       "  11  24.00  0.0    1.0\n",
       "  12  17.00  0.0    1.0\n",
       "  13  35.00  0.0    1.0\n",
       "  14  25.00  1.0    1.0\n",
       "  15  17.00  1.0    1.0\n",
       "  16  35.00  0.0    1.0\n",
       "  17  36.00  0.0    1.0\n",
       "  18  46.00  0.0    1.0\n",
       "  19  56.00  0.0    1.0,\n",
       "  'batch': 0     H29\n",
       "  1     H29\n",
       "  2     H29\n",
       "  3     H29\n",
       "  4     H29\n",
       "  5     H29\n",
       "  6     H29\n",
       "  7     H29\n",
       "  8     H29\n",
       "  9     H29\n",
       "  10    H29\n",
       "  11    H29\n",
       "  12    H29\n",
       "  13    H29\n",
       "  14    H29\n",
       "  15    H29\n",
       "  16    H29\n",
       "  17    H29\n",
       "  18    H29\n",
       "  19    H29\n",
       "  dtype: category\n",
       "  Categories (2, object): ['H0', 'H29'],\n",
       "  'ref_batch': 'H0',\n",
       "  'eb': True,\n",
       "  'parametric': True,\n",
       "  'mean_only': False}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_=dc.distributedCombat_site(\n",
    "    pd.DataFrame(new_site_data), bat, new_site_covars[['ages','sex','group']], \n",
    "    file=\"new_site_harmonized.pickle\",\n",
    "     central_out=dc_out, \n",
    "    ref_batch = 'H0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1dd740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01966927, -0.09759911, -0.111213  , ...,  0.09385213,\n",
       "        0.08295549,  0.07320043])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done=pickle.load(open('new_site_harmonized.pickle', \"rb\"))\n",
    "done['estimates']['gamma_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "36316743",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sites=['H29']\n",
    "c_raw = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_smoothed_NewSite.hdf5', dataset='MELD_dataset_NewSiteH29.csv',\n",
    "                  data_dir=MELD_DATA_PATH)\n",
    "listids = c_raw.get_subject_ids(site_codes=new_sites, lesional_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f36d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=Preprocess(c_raw)\n",
    "DEMOGRAPHIC_FEATURES_FILE = \"demographics_qc_allgroups_with_H29.csv\"\n",
    "\n",
    "precombat_features=[]\n",
    "combat_subject_include = np.zeros(len(listids), dtype=bool)\n",
    "demos=[]\n",
    "for k, subject in enumerate(listids):\n",
    "    # get the reference index and cohort object for the site, 0 whole cohort, 1 new cohort\n",
    "    site_code_index = new_site_codes[k]\n",
    "    \n",
    "    subj = MeldSubject(subject, cohort=c_raw)\n",
    "    demo = subj.get_demographic_features(['Age at preop','Sex','group',],\n",
    "                                         csv_file = DEMOGRAPHIC_FEATURES_FILE)\n",
    "    demo[2]=demo[2]=='patient'\n",
    "    demos.append(demo)\n",
    "    # exclude outliers and subject without feature\n",
    "    if (subj.has_features('.on_lh.thickness.sm10.mgh')) :\n",
    "        lh = subj.load_feature_values('.on_lh.thickness.sm10.mgh', hemi=\"lh\")[c_raw.cortex_mask]\n",
    "        rh = subj.load_feature_values('.on_lh.thickness.sm10.mgh', hemi=\"rh\")[c_raw.cortex_mask]\n",
    "        combined_hemis = np.hstack([lh, rh])\n",
    "        precombat_features.append(combined_hemis)\n",
    "        combat_subject_include[k] = True\n",
    "    else:\n",
    "        combat_subject_include[k] = False\n",
    "\n",
    "#calculate distributed combat parameters for central site\n",
    "new_site_data = np.array(precombat_features).T\n",
    "demos = np.array(demos).astype(np.float64)\n",
    "demos = demos[combat_subject_include]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5af6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1722f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_site_covars = pd.DataFrame(demos,columns=['ages','sex','group'])\n",
    "new_site_covars = new_site_covars.reset_index()\n",
    "N=len(new_site_covars)\n",
    "bat = pd.Series(pd.Categorical(np.repeat(new_site_code, N),\n",
    "                               categories=['H0', new_site_code]))\n",
    "\n",
    "new_site_covars['site_scanner']=bat\n",
    "new_site_covars = new_site_covars[['ages','sex','group','site_scanner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73fa1b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step2\n",
      "Must specify filename to output results as a file. Currently saving output to current workspace only.\n"
     ]
    }
   ],
   "source": [
    "print('step1')\n",
    "dc.distributedCombat_site(new_site_data,\n",
    "                          bat, \n",
    "                          new_site_covars[['ages','sex','group']], \n",
    "                          file=\"new_site_summary.pickle\", \n",
    "                      ref_batch = 'H0')\n",
    "print('step2')\n",
    "\n",
    "dc_out = dc.distributedCombat_central(\n",
    "    [\"MELD.pickle\", \"new_site_summary.pickle\"], ref_batch = 'H0'\n",
    ")\n",
    "# third, use variance estimates from full MELD cohort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7e9c6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/software/main_meld/meld_classifier/meld_classifier/distributedCombat_helpers.py:229: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  np.linalg.inv(np.matmul(batch_design.transpose(), batch_design)),\n",
      "/home/kw350/software/main_meld/meld_classifier/meld_classifier/distributedCombat_helpers.py:232: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  gamma_hat = np.matmul(gamma_hat, s_data.transpose())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dc_out['var_pooled'] = pd.read_pickle('MELD_var.pickle').ravel()\n",
    "new_site_covars[['ages','sex','group']]\n",
    "for c in ['ages','sex','group']:\n",
    "    new_site_covars[c]=new_site_covars[c].astype(np.float64)\n",
    "print('step3')\n",
    "\n",
    "_=dc.distributedCombat_site(\n",
    "    pd.DataFrame(new_site_data), bat, new_site_covars[['ages','sex','group']], \n",
    "    file=\"new_site_harmonized.pickle\",\n",
    "     central_out=dc_out, \n",
    "    ref_batch = 'H0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a8bdad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h29=pickle.load(open('new_site_harmonized.pickle', \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f7950b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f='/rds/user/kw350/rds-kw350-meld/meld_data/Data/Combat_parameters_6_shrink_with_H29.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f844d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f='/rds/user/kw350/rds-kw350-meld/meld_data/Data/Combat_parameters_6_shrink.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1ca276e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['.on_lh.curv.sm5.mgh', '.on_lh.gm_FLAIR_0.25.sm10.mgh', '.on_lh.gm_FLAIR_0.5.sm10.mgh', '.on_lh.gm_FLAIR_0.75.sm10.mgh', '.on_lh.gm_FLAIR_0.sm10.mgh', '.on_lh.pial.K_filtered.sm20.mgh', '.on_lh.sulc.sm5.mgh', '.on_lh.thickness.sm10.mgh', '.on_lh.w-g.pct.sm10.mgh', '.on_lh.wm_FLAIR_0.5.sm10.mgh', '.on_lh.wm_FLAIR_1.sm10.mgh']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r=    h5py.File(f, \"r+\")\n",
    "print(r.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94002d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gamma_hat', 'delta_hat', 'gamma_star', 'delta_star', 'gamma_bar', 't2', 'a_prior', 'b_prior', 'stand_mean', 'mod_mean', 'var_pooled', 'beta_hat', 'mod', 'batch', 'ref_batch', 'eb', 'parametric', 'mean_only'])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h29['estimates'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1fb01d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['a_prior', 'b_prior', 'batches', 'delta.star', 'delta_hat', 'gamma.star', 'gamma_bar', 'gamma_hat', 'stand.mean', 't2', 'var.pooled']>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['.on_lh.thickness.sm10.mgh'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "08e321d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_trans = {  'var_pooled' :'var.pooled', 'stand_mean':'stand.mean',\n",
    "             'gamma_star':'gamma.star',\n",
    "              'delta_star':'delta.star'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c777f0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29803439,  0.16412822,  1.1110283 , ..., -0.32362026,\n",
       "       -0.26585187, -0.22648567])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h29['estimates']['gamma_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7c22691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02535067, -0.74980438, -0.95659354, ...,  0.18538668,\n",
       "         0.14399838,  0.11005745],\n",
       "       [ 0.12462134, -0.05315445,  0.19109114, ...,  0.23696148,\n",
       "         0.19060924,  0.15195985],\n",
       "       [-0.59141207, -0.47368598, -0.57783468, ..., -0.38959143,\n",
       "        -0.46579725, -0.53311225],\n",
       "       ...,\n",
       "       [-0.25978467, -0.29191566, -0.23886391, ..., -0.05283375,\n",
       "        -0.05584079, -0.05809188],\n",
       "       [-0.90145029, -0.31910456, -1.12513365, ..., -0.83040208,\n",
       "        -0.79822555, -0.76691451],\n",
       "       [ 0.770907  ,  0.15374313,  0.40022076, ...,  0.17672618,\n",
       "         0.19807367,  0.21465289]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['.on_lh.thickness.sm10.mgh']['gamma.star'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "89b07a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/.conda/envs/meld_classifier/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 H10_3T -0.17512065469221436 -0.46076543021061256\n",
      "1 H11_3T 0.08613978095634695 0.010672936773568292\n",
      "2 H12_15T -0.11011650497637472 -0.29329712509459055\n",
      "3 H12_3T 0.15478424337310942 -0.4618730773021159\n",
      "4 H14_3T 0.04596097762653507 -0.08606652687193211\n",
      "5 H15_3T -0.022917329599929 0.05862722115331445\n",
      "6 H16_3T -0.011435288837346702 -0.38140162178564674\n",
      "7 H17_15T -0.017434629413527167 -0.30617652592195443\n",
      "8 H17_3T -0.1753136814625555 -0.30456195274687564\n",
      "9 H18_3T 0.08101200389555117 0.2543102877045795\n",
      "10 H19_3T -0.1278279511238725 -0.22684608615719135\n",
      "11 H21_15T 0.04421857739202991 0.3350154904011703\n",
      "12 H21_3T 0.006750909155078071 0.2960732567372143\n",
      "13 H23_15T -0.13743501391357327 0.13055858643521573\n",
      "14 H24_3T 0.10240205590949543 0.40669525998134837\n",
      "15 H26_15T 0.1621785015042939 -0.22876901508884642\n",
      "16 H26_3T -0.10375838230130928 -0.13925404907700858\n",
      "17 H29_3T 0.9482784522174545 0.9963710927184899\n",
      "18 H2_15T -0.03973727756104102 -0.08125715456205024\n",
      "19 H2_3T 0.12166692323687696 0.029055339488444343\n",
      "20 H3_3T -0.14817756229691692 -0.4728062655136555\n",
      "21 H4_15T 0.08080110460035966 0.11071414521919855\n",
      "22 H4_3T -0.013303518743161435 0.27838362828267843\n",
      "23 H5_3T -0.3322101668064368 -0.27999487650285476\n",
      "24 H6_3T -0.01569229734988513 -0.04003597963278337\n",
      "25 H7_3T -0.19279267791979388 -0.11790393016413324\n",
      "26 H9_3T -0.13290658400287594 0.43699911026136334\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(r['.on_lh.thickness.sm10.mgh']['batches'].attrs[\"values\"].astype(np.str)):\n",
    "    print(i,s,np.corrcoef(h29['estimates']['delta_star'],\n",
    "           r['.on_lh.thickness.sm10.mgh']['delta.star'][i])[0,1],\n",
    "      np.corrcoef(h29['estimates']['gamma_star'],\n",
    "           r['.on_lh.thickness.sm10.mgh']['gamma.star'][i])[0,1],\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b816931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kw350/.conda/envs/meld_classifier/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([17]),)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(r['.on_lh.thickness.sm10.mgh']['batches'].attrs[\"values\"].astype(np.str)==['H29_3T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d101bf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13729922, 0.13914082, 0.10271709, ..., 0.21593729, 0.22392766,\n",
       "       0.23028035])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h29['estimates']['var_pooled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "828913c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_pooled (293804,) (293804, 1)\n",
      "stand_mean (293804, 52) (293804,)\n",
      "gamma_star (293804,) (27, 293804)\n",
      "delta_star (293804,) (27, 293804)\n"
     ]
    }
   ],
   "source": [
    "for k in dict_trans.keys():\n",
    "    print(k,h29['estimates'][k].shape,r['.on_lh.thickness.sm10.mgh'][dict_trans[k]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57aa7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c77af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meld_classifier import distributedCombat_helpers as helpers\n",
    "\n",
    "def distributedCombat_site(\n",
    "    dat,\n",
    "    batch,\n",
    "    mod=None,\n",
    "    ref_batch=None,\n",
    "    central_out=None,\n",
    "    eb=True,\n",
    "    parametric=True,\n",
    "    mean_only=False,\n",
    "    verbose=False,\n",
    "    file=None,\n",
    "):\n",
    "    if file is None:\n",
    "        file = \"distributedCombat_site.pickle\"\n",
    "        print(\n",
    "            \"Must specify filename to output results as a file. Currently saving output to current workspace only.\"\n",
    "        )\n",
    "    if isinstance(central_out, str):\n",
    "        central_out = pd.read_pickle(central_out)\n",
    "    hasNAs = np.isnan(dat).any(axis=None)\n",
    "    if verbose and hasNAs:\n",
    "        print(\"[neuroCombat] WARNING: NaNs detected in data\")\n",
    "    if mean_only:\n",
    "        print(\"[neuroCombat] Performing ComBat with mean only\")\n",
    "\n",
    "    ##################### Getting design ############################\n",
    "    data_dict = helpers.getDataDictDC(\n",
    "        batch, mod, verbose=verbose, mean_only=mean_only, ref_batch=ref_batch\n",
    "    )\n",
    "\n",
    "    design = data_dict[\"design\"].copy()\n",
    "    #################################################################\n",
    "\n",
    "    ############### Site matrices for standardization ###############\n",
    "    # W^T W used in LS estimation\n",
    "    ls_site = []\n",
    "    ls_site.append(np.dot(design.transpose(), design))\n",
    "    ls_site.append(np.dot(design.transpose(), dat.transpose()))\n",
    "\n",
    "    data_dict_out = data_dict.copy()\n",
    "    data_dict_out[\"design\"] = None\n",
    "\n",
    "    # new data_dict with batches within current site\n",
    "    incl_bat = [x > 0 for x in data_dict[\"n_batches\"]]\n",
    "    data_dict_site = data_dict.copy()\n",
    "    data_dict_site[\"batches\"] = [\n",
    "        data_dict[\"batches\"][i] for i in range(len(data_dict[\"batches\"])) if incl_bat[i]\n",
    "    ]\n",
    "    data_dict_site[\"n_batch\"] = incl_bat.count(True)\n",
    "    data_dict_site[\"n_batches\"] = [\n",
    "        data_dict[\"n_batches\"][i]\n",
    "        for i in range(len(data_dict[\"n_batches\"]))\n",
    "        if incl_bat[i]\n",
    "    ]\n",
    "    data_dict_site[\"batch_design\"] = data_dict[\"batch_design\"].loc[:, incl_bat]\n",
    "\n",
    "    # remove reference batch information if reference batch is not in site\n",
    "    if ref_batch is not None:\n",
    "        if data_dict_site[\"ref\"] in data_dict_site[\"batch\"].unique():\n",
    "            data_dict_site[\"ref\"] = np.where(\n",
    "                np.any(data_dict_site[\"batch\"] == ref_batch)\n",
    "            )[0][0]\n",
    "        else:\n",
    "            data_dict_site[\"ref\"] = None\n",
    "            data_dict_site[\"ref_batch\"] = None\n",
    "\n",
    "    if central_out is None:\n",
    "        site_out = {\n",
    "            \"ls_site\": ls_site,\n",
    "            \"data_dict\": data_dict,\n",
    "            \"sigma_site\": None,\n",
    "        }\n",
    "        with open(file, \"wb\") as handle:\n",
    "            pickle.dump(site_out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        return site_out\n",
    "\n",
    "    # If beta.estimates given, get summary statistics for sigma estimation\n",
    "\n",
    "    if \"var_pooled\" not in central_out or central_out[\"var_pooled\"] is None:\n",
    "        sigma_site = helpers.getSigmaSummary(dat, data_dict, design, hasNAs, central_out)\n",
    "        site_out = {\n",
    "            \"ls_site\": ls_site,\n",
    "            \"data_dict\": data_dict,\n",
    "            \"sigma_site\": sigma_site,\n",
    "        }\n",
    "        with open(file, \"wb\") as handle:\n",
    "            pickle.dump(site_out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        return site_out\n",
    "\n",
    "    stdObjects = helpers.getStandardizedDataDC(\n",
    "        dat=dat,\n",
    "        data_dict=data_dict,\n",
    "        design=design,\n",
    "        hasNAs=hasNAs,\n",
    "        central_out=central_out,\n",
    "    )\n",
    "    s_data = stdObjects[\"s_data\"]\n",
    "    return s_data,data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2490281",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data,data_dict=distributedCombat_site(\n",
    "    new_site_data, bat, new_site_covars[['ages','sex','group']], \n",
    "    file=\"new_site_harmonized.pickle\",\n",
    "     central_out=dc_out, \n",
    "    ref_batch = 'H0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3565a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = data_dict[\"batches\"]\n",
    "i=batches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d19811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.var(s_data.iloc[:100, i[0]].astype(np.float64),axis=1,ddof=1)\n",
    "\n",
    "v1=np.diagonal(np.cov(s_data.iloc[:100, i[0]].astype(np.float64), rowvar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8cca7987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.220446e-16\n",
       "1     0.000000e+00\n",
       "2     0.000000e+00\n",
       "3    -1.110223e-16\n",
       "4    -2.220446e-16\n",
       "          ...     \n",
       "95    0.000000e+00\n",
       "96    0.000000e+00\n",
       "97   -2.220446e-16\n",
       "98    0.000000e+00\n",
       "99   -2.220446e-16\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "done=pickle.load(open('new_site_harmonized.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22c847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 calculates something. Outputs 2 pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67784096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combat] Found 2 batches\n",
      "[combat] Using batch=H0 as a reference batch\n",
      "[combat] Adjusting for  3  covariate(s) or covariate level(s)\n",
      "[combat] Found 2 batches\n",
      "[combat] Using batch=H0 as a reference batch\n",
      "[combat] Adjusting for  3  covariate(s) or covariate level(s)\n"
     ]
    }
   ],
   "source": [
    "#step 1\n",
    "batch_col = \"site_scanner\"\n",
    "site_outs = []\n",
    "outs=[]\n",
    "batch = pd.Series(covars[batch_col],dtype=\"category\")\n",
    "for b in covars[batch_col].unique():\n",
    "    s = list(map(lambda x: x == b, covars[batch_col]))\n",
    "    df = pd.DataFrame(precombat_features[:, s])\n",
    "    bat = batch[s]\n",
    "    mod=covars[['ages','sex','group']][s]\n",
    "    f = \"site_out_\" + str(b) + \"step1.pickle\"\n",
    "    out = dc.distributedCombat_site(df, bat, mod, verbose=True, file=f, ref_batch=\"H0\")\n",
    "    site_outs.append(f)\n",
    "    outs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344508b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls1 = np.array([x[\"ls_site\"][0] for x in outs],dtype=float)\n",
    "# ls2 = np.array([x[\"ls_site\"][1] for x in outs],dtype=float)\n",
    "# ls1 = np.cumsum(ls1, axis=0)[-1]\n",
    "# ls2 = np.cumsum(ls2, axis=0)[-1]\n",
    "# B_hat = np.matmul(np.transpose(np.linalg.inv(ls1)), ls2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b827a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must specify filename to output results as a file. Currently saving output to current workspace only.\n"
     ]
    }
   ],
   "source": [
    "central = dc.distributedCombat_central(site_outs,\n",
    "                                                         ref_batch=\"H0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9a61304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_hat': array([[ 2.87273836e+00,  2.76082726e+00,  2.94237274e+00, ...,\n",
       "          3.27097790e+00,  3.26482042e+00,  3.25678282e+00],\n",
       "        [ 2.43385064e-02,  2.62450668e-02,  2.83698883e-03, ...,\n",
       "          1.14721933e-02,  9.84297745e-03,  8.66022892e-03],\n",
       "        [-1.31384290e-03, -6.43232527e-03, -8.84719894e-03, ...,\n",
       "         -1.85443642e-03, -1.75913807e-03, -1.68640889e-03],\n",
       "        [-2.48058980e-02, -1.98598958e-02, -2.29820715e-02, ...,\n",
       "         -9.17674098e-02, -9.89966526e-02, -1.04134338e-01],\n",
       "        [-6.53136787e-02, -3.60148342e-02, -3.09331465e-02, ...,\n",
       "         -7.54054490e-02, -6.50532748e-02, -5.55797672e-02]]),\n",
       " 'stand_mean': array([[2.87273836, 2.87273836, 2.87273836, ..., 2.87273836, 2.87273836,\n",
       "         2.87273836],\n",
       "        [2.76082726, 2.76082726, 2.76082726, ..., 2.76082726, 2.76082726,\n",
       "         2.76082726],\n",
       "        [2.94237274, 2.94237274, 2.94237274, ..., 2.94237274, 2.94237274,\n",
       "         2.94237274],\n",
       "        ...,\n",
       "        [3.2709779 , 3.2709779 , 3.2709779 , ..., 3.2709779 , 3.2709779 ,\n",
       "         3.2709779 ],\n",
       "        [3.26482042, 3.26482042, 3.26482042, ..., 3.26482042, 3.26482042,\n",
       "         3.26482042],\n",
       "        [3.25678282, 3.25678282, 3.25678282, ..., 3.25678282, 3.25678282,\n",
       "         3.25678282]]),\n",
       " 'var_pooled': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6841d5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ages</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>53.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>6.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>14.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>14.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ages  sex  group\n",
       "0    21.00  1.0   True\n",
       "1    26.00  1.0   True\n",
       "2    25.00  1.0   True\n",
       "3    31.00  0.0   True\n",
       "4    25.75  0.0   True\n",
       "..     ...  ...    ...\n",
       "470  53.00  1.0   True\n",
       "471   6.50  1.0  False\n",
       "472  14.25  0.0  False\n",
       "473  14.00  0.0  False\n",
       "474   6.00  0.0  False\n",
       "\n",
       "[475 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb8ed4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ages</th>\n",
       "      <th>sex</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>53.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>6.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>14.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>14.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ages  sex  group\n",
       "0    21.00  1.0   True\n",
       "1    26.00  1.0   True\n",
       "2    25.00  1.0   True\n",
       "3    31.00  0.0   True\n",
       "4    25.75  0.0   True\n",
       "..     ...  ...    ...\n",
       "470  53.00  1.0   True\n",
       "471   6.50  1.0  False\n",
       "472  14.25  0.0  False\n",
       "473  14.00  0.0  False\n",
       "474   6.00  0.0  False\n",
       "\n",
       "[475 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60895591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combat] Found 2 batches\n",
      "[combat] Using batch=H0 as a reference batch\n",
      "[combat] Adjusting for  3  covariate(s) or covariate level(s)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Number of manager items must equal union of block items\n# manager items: 5, # tot_items: 293804",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8030/1697591833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"site_out_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     out = dc.distributedCombat_site(\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"H0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0msite_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/main_meld/neuroCombat/distributedCombat/distributedCombat.py\u001b[0m in \u001b[0;36mdistributedCombat_site\u001b[0;34m(dat, batch, mod, ref_batch, central_out, eb, parametric, mean_only, verbose, file)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"var_pooled\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentral_out\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcentral_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var_pooled\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0msigma_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSigmaSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasNAs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentral_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         site_out = {\n\u001b[1;32m    117\u001b[0m             \u001b[0;34m\"ls_site\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mls_site\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/main_meld/neuroCombat/distributedCombat/distributedCombat_helpers.py\u001b[0m in \u001b[0;36mgetSigmaSummary\u001b[0;34m(dat, data_dict, design, hasNAs, central_out)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             var_pooled = (\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0;34m/\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                 ]\n\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0;34m\"Number of manager items must equal union of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0;34mf\"block items\\n# manager items: {len(self.items)}, # \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;34mf\"tot_items: {tot_items}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Number of manager items must equal union of block items\n# manager items: 5, # tot_items: 293804"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Step 2\n",
    "site_outs = []\n",
    "for b in covars[batch_col].unique():\n",
    "    s = list(map(lambda x: x == b, covars[batch_col]))\n",
    "    df = pd.DataFrame(precombat_features[:, s])\n",
    "    bat = batch[s]\n",
    "    mod = covars[['ages','sex','group']][s]  \n",
    "    f = \"site_out_\" + str(b) + \"step2.pickle\"\n",
    "    out = dc.distributedCombat_site(\n",
    "        df, bat, mod, verbose=True, central_out=central, file=f, ref_batch=\"H0\"\n",
    "    )\n",
    "    site_outs.append(f)\n",
    "\n",
    "central = dc.distributedCombat_central(site_outs, ref_batch=\"H0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 get the data out\n",
    "b = 'H1'\n",
    "s = list(map(lambda x: x == b, covars[batch_col]))\n",
    "df = pd.DataFrame(precombat_features[:, s])\n",
    "bat = batch[s]\n",
    "mod = covars[['ages','sex','group']][s]  \n",
    "f = \"site_out_\" + str(b) + \".pickle\"\n",
    "out = dc.distributedCombat_site(\n",
    "        df, bat, x, central_out=central, file=f, ref_batch=\"H0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_outs = []\n",
    "for b in covars[batch_col].unique():\n",
    "    s = list(map(lambda x: x == b, covars[batch_col]))\n",
    "    df = dat.loc[:, s]\n",
    "    bat = covars[batch_col][s]\n",
    "    x = mod.loc[s, :]\n",
    "    f = \"site_out_\" + str(b) + \".pickle\"\n",
    "    out = dc.distributedCombat_site(df, bat, x, verbose=True, file=f, ref_batch=\"1\")\n",
    "    site_outs.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82083850",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_subject_ids = c_combat.get_subject_ids(lesional_only=False)\n",
    "combined_ids = ref_subject_ids + self.subject_ids\n",
    "combat_subject_include = np.zeros(len(combined_ids), dtype=bool)\n",
    "new_site_codes = np.ones(len(combined_ids), dtype=int)\n",
    "new_site_codes[: len(ref_subject_ids)] = 0\n",
    "# load in both combat normalised and new cohort\n",
    "precombat_features = []\n",
    "cohorts = [ref_cohort, self.cohort]\n",
    "# need pre combat and post combat feature names, loading in post for the whole cohort,\n",
    "# pre for the new cohort.\n",
    "post_combat_feature_name = self.feat.combat_feat(feature_name)\n",
    "feature_names = [post_combat_feature_name, feature_name]\n",
    "for k, subject in enumerate(combined_ids):\n",
    "    # get the reference index and cohort object for the site, 0 whole cohort, 1 new cohort\n",
    "    site_code_index = new_site_codes[k]\n",
    "    cohort = cohorts[site_code_index]\n",
    "    subj = MeldSubject(subject, cohort=cohort)\n",
    "    # exclude outliers and subject without feature\n",
    "    if (subj.has_features(feature_names[site_code_index])) & (subject not in outliers):\n",
    "        lh = subj.load_feature_values(feature_names[site_code_index], hemi=\"lh\")[self.cohort.cortex_mask]\n",
    "        rh = subj.load_feature_values(feature_names[site_code_index], hemi=\"rh\")[self.cohort.cortex_mask]\n",
    "        combined_hemis = np.hstack([lh, rh])\n",
    "        precombat_features.append(combined_hemis)\n",
    "        combat_subject_include[k] = True\n",
    "    else:\n",
    "        combat_subject_include[k] = False\n",
    "if precombat_features:\n",
    "    precombat_features = np.array(precombat_features)\n",
    "    # load in covariates - age, sex, group, site and scanner,\n",
    "    # set site_scanner to 0 for existing cohort\n",
    "    covars = pd.concat([self.load_covars(ref_subject_ids), self.covars])\n",
    "    covars[\"site_scanner\"][: len(ref_subject_ids)] = \"H0\"\n",
    "    covars = covars[combat_subject_include].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9809d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28282/3686028944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcovars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"site_out_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "site_outs = []\n",
    "for b in covars[batch_col].unique():\n",
    "    s = list(map(lambda x: x == b, covars[batch_col]))\n",
    "    df = dat.loc[:, s]\n",
    "    bat = covars[batch_col][s]\n",
    "    f = \"site_out_\" + str(b) + \".pickle\"\n",
    "    out = dc.distributedCombat_site(df, bat, verbose=True, file=f, ref_batch=\"H0\")\n",
    "    site_outs.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combat_new_site(\n",
    "        self,\n",
    "        feature_name,\n",
    "        new_site_code,\n",
    "        ref_cohort,\n",
    "        new_outliers_file=None,\n",
    "    ):\n",
    "        \"\"\"Harmonise new site data to post-combat whole cohort and save in\n",
    "        new hdf5 file. New sites are run individually currently.\n",
    "        assumes that the base cohort is the post-combat cohort\n",
    "        Args:\n",
    "            feature_name (str): name of the feature\n",
    "            outliers_file : outliers file for the new cohort\n",
    "\n",
    "        \"\"\"\n",
    "        # read morphological outliers from new cohort only\n",
    "        if new_outliers_file is not None:\n",
    "            outliers = list(pd.read_csv(os.path.join(BASE_PATH, new_outliers_file), header=0)[\"ID\"])\n",
    "        else:\n",
    "            outliers = []\n",
    "\n",
    "        # make empty for all subjects\n",
    "        ref_subject_ids = ref_cohort.get_subject_ids(lesional_only=False)\n",
    "        combined_ids = ref_subject_ids + self.subject_ids\n",
    "        combat_subject_include = np.zeros(len(combined_ids), dtype=bool)\n",
    "        new_site_codes = np.ones(len(combined_ids), dtype=int)\n",
    "        new_site_codes[: len(ref_subject_ids)] = 0\n",
    "        # load in both combat normalised and new cohort\n",
    "        precombat_features = []\n",
    "        cohorts = [ref_cohort, self.cohort]\n",
    "        # need pre combat and post combat feature names, loading in post for the whole cohort,\n",
    "        # pre for the new cohort.\n",
    "        post_combat_feature_name = self.feat.combat_feat(feature_name)\n",
    "        feature_names = [post_combat_feature_name, feature_name]\n",
    "        for k, subject in enumerate(combined_ids):\n",
    "            # get the reference index and cohort object for the site, 0 whole cohort, 1 new cohort\n",
    "            site_code_index = new_site_codes[k]\n",
    "            cohort = cohorts[site_code_index]\n",
    "            subj = MeldSubject(subject, cohort=cohort)\n",
    "            # exclude outliers and subject without feature\n",
    "            if (subj.has_features(feature_names[site_code_index])) & (subject not in outliers):\n",
    "                lh = subj.load_feature_values(feature_names[site_code_index], hemi=\"lh\")[self.cohort.cortex_mask]\n",
    "                rh = subj.load_feature_values(feature_names[site_code_index], hemi=\"rh\")[self.cohort.cortex_mask]\n",
    "                combined_hemis = np.hstack([lh, rh])\n",
    "                precombat_features.append(combined_hemis)\n",
    "                combat_subject_include[k] = True\n",
    "            else:\n",
    "                combat_subject_include[k] = False\n",
    "        if precombat_features:\n",
    "            precombat_features = np.array(precombat_features)\n",
    "            # load in covariates - age, sex, group, site and scanner,\n",
    "            # set site_scanner to 0 for existing cohort\n",
    "            covars = pd.concat([self.load_covars(ref_subject_ids), self.covars])\n",
    "            covars[\"site_scanner\"][: len(ref_subject_ids)] = \"H0\"\n",
    "            covars = covars[combat_subject_include].copy()\n",
    "\n",
    "            # function to check for single subjects\n",
    "            covars, precombat_features = self.remove_isolated_subs(covars, precombat_features)\n",
    "\n",
    "            dict_combat = neuroCombat(\n",
    "                precombat_features.T,\n",
    "                covars,\n",
    "                batch_col=\"site_scanner\",\n",
    "                categorical_cols=[\"sex\", \"group\"],\n",
    "                continuous_cols=[\"ages\"],\n",
    "                ref_batch=\"H0\",\n",
    "            )\n",
    "\n",
    "            print(\"Combat finished \\n Saving data\")\n",
    "            # only save out new subjects\n",
    "            ids_to_save = np.array(covars[covars[\"site_scanner\"] != \"H0\"][\"ID\"])\n",
    "            self.save_cohort_features(\n",
    "                post_combat_feature_name, dict_combat[\"data\"].T[covars[\"site_scanner\"] != \"H0\"], ids_to_save\n",
    "            )\n",
    "        else:\n",
    "            print('No data to combat harmonised')\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meld_classifier",
   "language": "python",
   "name": "meld_classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
